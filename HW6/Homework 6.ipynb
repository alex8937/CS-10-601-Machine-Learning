{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $Z^\\left(i\\right) \\sim Categorical\\left(\\pi\\right)$ and $X^\\left(i\\right) \\mid Z^\\left(i\\right) \\sim Categorical\\left(\\theta\\right)$, we have\n",
    "\n",
    "$$P\\left(Z^{\\left(i\\right)}\\right) = \\prod_{k = 1}^{K}\\pi_{k}^{\\mathbb{1}\\{Z^\\left(i\\right)=k\\}}$$\n",
    "$$P\\left(X^{\\left ( i \\right )} \\mid Z^{\\left ( i \\right )}\\right) =  \\prod_{k = 1}^{K} \\prod_{j = 1}^{J}\\theta_{kj}^{\\mathbb{1}\\{X^{\\left(i\\right)=j}\\}\\mathbb{1}\\{Z^{\\left(i\\right)=k}\\}}$$\n",
    "\n",
    "Then, the joint distirbution becomes\n",
    "\n",
    "$$P\\left(X^{\\left(i\\right)},Z^{\\left(i\\right)}\\right) = \\prod_{k = 1}^{K}\\left[\\pi_{k}\\prod_{j = 1}^{J}\\theta_{kj}^{\\mathbb{1}\\{X^{\\left(i\\right)=j}\\}}\\right]^{\\mathbb{1}\\{Z^{\\left(i\\right)=k}\\}}$$\n",
    "\n",
    "Assume all samples are drawn i.i.d, then\n",
    "\n",
    "$$\\begin{align}\n",
    "P\\left(X,Z\\right) &= \\prod_{i=1}^{N}P\\left(X^{\\left(i\\right)},Z^{\\left(i\\right)}\\right) \\\\\n",
    "&= \\prod_{i=1}^{N}\\prod_{k = 1}^{K}\\left[\\pi_{k}\\prod_{j = 1}^{J}\\theta_{kj}^{\\mathbb{1}\\{X^{\\left(i\\right)=j}\\}}\\right]^{\\mathbb{1}\\{Z^{\\left(i\\right)=k}\\}}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distribution can be calculated using the definition of conditional distribution\n",
    "\n",
    "$$\\begin{align}\n",
    "   P\\left( Z\\mid X \\right)&=\\prod\\limits_{i=1}^{N}{P\\left( {{Z}^{\\left( i \\right)}}\\mid {{X}^{\\left( i \\right)}} \\right)} \\\\ \n",
    " & =\\prod\\limits_{i=1}^{N}{\\frac{P\\left( {{X}^{\\left( i \\right)}},{{Z}^{\\left( i \\right)}} \\right)}{\\sum\\limits_{{{Z}^{\\left( i \\right)}}=1}^{K}{P\\left( {{X}^{\\left( i \\right)}},{{Z}^{\\left( i \\right)}} \\right)}}} \\\\ \n",
    " & =\\prod\\limits_{i=1}^{N}{\\frac{\\prod\\limits_{k=1}^{K}{{{\\left[ {{\\pi }_{k}}\\prod\\limits_{j=1}^{J}{\\theta _{kj}^{\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}}} \\right]}^{\\mathbb{1}\\{{{Z}^{\\left( i \\right)=k}}\\}}}}}{\\sum\\limits_{{{Z}^{\\left( i \\right)}}=1}^{K}{{{\\pi }_{k}}\\prod\\limits_{j=1}^{J}{\\theta _{kj}^{\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}}}}}} \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The log likelihood is\n",
    "$$\\log P\\left( X,Z \\right)=\\sum\\limits_{i=1}^{N}{\\sum\\limits_{k=1}^{K}{\\mathbb{1}\\{{{Z}^{\\left( i \\right)=k}}\\}\\left[ \\log {{\\pi }_{k}}+\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}\\sum\\limits_{j=1}^{J}{\\log {{\\theta }_{kj}}} \\right]}}$$\n",
    "\n",
    "So the expectation of log likelihood is\n",
    "\n",
    "$$\\begin{align}\n",
    "Q\\left( {\\Theta }'|\\Theta  \\right)=&{{E}_{Z|X}}\\log P\\left( X,Z \\right) \\\\\n",
    "=&\\sum\\limits_{i=1}^{N}{\\sum\\limits_{k=1}^{K}{\\gamma_{ik}\\left[ \\log {{\\pi }_{k}}+\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}\\sum\\limits_{j=1}^{J}{\\log {{\\theta }_{kj}}} \\right]}}\n",
    "\\end{align}$$\n",
    "where\n",
    "$$\\gamma_{ik} = {\\frac{{{{\\left[ {{\\pi }_{k}}\\prod\\limits_{j=1}^{J}{\\theta _{kj}^{\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}}} \\right]}^{\\mathbb{1}\\{{{Z}^{\\left( i \\right)=k}}\\}}}}}{\\sum\\limits_{{{Z}^{\\left( i \\right)}}=1}^{K}{{{\\pi }_{k}}\\prod\\limits_{j=1}^{J}{\\theta _{kj}^{\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}}}}}}$$\n",
    "\n",
    "$\\gamma_{ik}$ denotes the probably of sample $\\left(i\\right)$ having $Z^{\\left(i\\right)} = k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To\n",
    "\n",
    "$$\\underset{{{\\pi }_{k}}}{\\mathop{Arg\\max }}\\,Q\\left( {\\Theta }'|\\Theta  \\right)=\\underset{{{\\pi }_{k}}}{\\mathop{Arg\\max }}\\sum\\limits_{i=1}^{N}{\\sum\\limits_{k=1}^{K}{{{\\gamma }_{ik}}\\left[ \\log {{\\pi }_{k}}+\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}\\sum\\limits_{j=1}^{J}{\\log {{\\theta }_{kj}}} \\right]}}$$\n",
    "\n",
    "the Lagrangian becomes\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathcal{L}\\left(\\pi_{k}\\right) =\\sum\\limits_{i=1}^{N}{\\sum\\limits_{k=1}^{K}{{{\\gamma }_{ik}}\\left[ \\log {{\\pi }_{k}}+\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}\\sum\\limits_{j=1}^{J}{\\log {{\\theta }_{kj}}} \\right]}} + \\lambda \\left(\\sum\\limits_{k=1}^{K}\\pi_{k}\\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Let\n",
    "\n",
    "$$\\begin{align}\n",
    "&\\frac{\\partial \\mathcal{L}\\left( {{\\pi }_{k}} \\right)}{\\partial {{\\pi }_{k}}}=\\sum\\limits_{i=1}^{N}{\\frac{{{\\gamma }_{ik}}}{{{\\pi }_{k}}}}+\\lambda =0 \\\\\n",
    "\\Rightarrow & {\\pi _k} =  - \\frac{1}{\\lambda }\\sum\\limits_{i = 1}^N {{\\gamma _{ik}}}  \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "Using the definitions of $ \\sum\\limits_{k = 1}^K\\pi_{k} = 1$ and $\\sum\\limits_{i = 1}^N {\\sum\\limits_{k = 1}^K {\\gamma_{jk}}} = N$, we can obtain\n",
    "\n",
    "$$\\lambda  = \\lambda \\sum\\limits_{k = 1}^K {{\\pi _k}}  =  - \\sum\\limits_{i = 1}^N {\\sum\\limits_{k = 1}^K {{\\gamma _{ik}}} }  =  - N$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$${\\pi _k} =  - \\frac{1}{N}\\sum\\limits_{i = 1}^N {{\\gamma _{ik}}}$$\n",
    "\n",
    "By the same token,\n",
    "\n",
    "$$\\mathcal{L}\\left( {{\\theta }_{jk}} \\right)=\\sum\\limits_{i=1}^{N}{\\sum\\limits_{k=1}^{K}{{{\\gamma }_{ik}}\\left[ \\log {{\\pi }_{k}}+\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}\\sum\\limits_{j=1}^{J}{\\log {{\\theta }_{kj}}} \\right]}}+\\beta \\left( \\sum\\limits_{k=1}^{K}{\\sum\\limits_{j=1}^{J}{{{\\theta }_{jk}}}} \\right)$$\n",
    "\n",
    "Let \n",
    "$$\\begin{align}\n",
    "  & \\frac{\\partial \\mathcal{L}\\left( {{\\theta }_{kj}} \\right)}{\\partial {{\\theta }_{jk}}}=\\sum\\limits_{i=1}^{N}{\\frac{{{\\gamma }_{ik}}\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}}{{{\\theta }_{kj}}}}+\\beta =0 \\\\ \n",
    " & \\Rightarrow {{\\theta }_{jk}}=-\\frac{1}{\\beta }\\sum\\limits_{i=1}^{N}{{{\\gamma }_{ik}}\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\}} \\\\ \n",
    "\\end{align}$$\n",
    "\n",
    "Using the definitions of $ \\sum\\limits_{j = 1}^J\\theta_{jk} = 1$, we can obtain\n",
    "\n",
    "$$\\beta  = \\beta \\sum\\limits_{j = 1}^J\\theta_{jk}  =  - \\sum\\limits_{i = 1}^N {\\sum\\limits_{j = 1}^J \\gamma_{ik}\\mathbb{1}\\{{{X}^{\\left( i \\right)=j}}\\} } $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$${\\theta _{jk}} = \\frac{{\\sum\\limits_{i = 1}^N {{\\gamma _{ik}}\\mathbb{1}\\{ {X^{\\left( i \\right) = j}}\\} } }}{{\\sum\\limits_{i = 1}^N {\\sum\\limits_{j = 1}^J {{\\gamma _{ik}}} \\mathbb{1}\\{ {X^{\\left( i \\right) = j}}\\} } }}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Select $h_{1}$ to be ($x = 0.75$ left: $o$, right: $+$);\n",
    "\n",
    "Select $h_{2}$ to be ($x = -0.25$ left: $+$, right: $o$);\n",
    "\n",
    "Select $h_{3}$ to be ($y =  0.75$ up: $o$, bottom: $+$);\n",
    "\n",
    "| $t$| $\\epsilon_{t}$| $\\alpha_{t}$| $Z_{t}$| $D_{t1}$  | $D_{t2}$| $D_{t3}$| $D_{t4}$| $D_{t5}$| $D_{t6}$| $D_{t7}$| $D_{t8}$ |\n",
    "| ------------- |:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n",
    "| 1| $\\frac{1}{4}$  | $ln\\sqrt3$ | $\\frac{\\sqrt3}{2}$ | $\\frac{1}{4}$  | $\\frac{1}{4}$  | $\\frac{1}{12}$  | $\\frac{1}{12}$ | $\\frac{1}{12}$ | $\\frac{1}{12}$ | $\\frac{1}{12}$ | $\\frac{1}{12}$ |\n",
    "| 2| $\\frac{1}{6}$  | $ln\\sqrt5$ | $\\frac{\\sqrt3}{2}$ | $\\frac{3}{20}$ | $\\frac{3}{20}$ | $\\frac{1}{20}$  | $\\frac{1}{20}$ | $\\frac{1}{4}$  | $\\frac{1}{4}$  | $\\frac{1}{20}$ | $\\frac{1}{20}$ |\n",
    "| 3| $\\frac{1}{10}$ | $ln3$      | $\\frac{3}{5}$      | $\\frac{1}{12}$ | $\\frac{1}{12}$ | $\\frac{1}{36}$  | $\\frac{1}{36}$ | $\\frac{5}{36}$  | $\\frac{5}{36}$  | $\\frac{1}{4}$ | $\\frac{1}{4}$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### b.\n",
    "\n",
    "AdaBoost has zero training error. AdaBoost combines several single decision stump as weak learners which forms nonlinear decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 3: Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No, the number of mistakes depends on the order of S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Assume there are $\\left(R/\\gamma\\right)^2 + 1$ points inside the ball of radius $R$ that can be \"shattered at margin $\\gamma$\" and assume we have a Perceptron to determine the decision boundary of the data. Since the data can be \"shatter at margin $\\gamma$\", which means that it can have any possible labels. That means, we can give the Perception in such an order that it will make $\\left(R/\\gamma\\right)^2 + 1$ mistakes in total. This is contradictory with the theroem that a Perception makes at most $\\left(R/\\gamma\\right)^2$ mistakes on the data within a radius $R$ and margin $\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 4: Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1 A proposed kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Mercer's theorem, for $x\\in\\mathbb{R}^{n}$, $K\\left(x, x'\\right) = I_{n\\times n}$ is a symmetric matrix and it is semi-positive definite since all its eigenvalues are ones. Therefore, $K$ is a legal kernel. \n",
    "\n",
    "For a collectin of $m$ points $x_1$, $x_2$, ..., $x_m$, the mapping function is $\\Phi(x_i)=e_{i} \\in \\mathbb{R}^m$. So\n",
    "\n",
    "$${{e}_{i}}\\cdot {{e}_{j}}=\\text{ }\\left\\{ \\begin{matrix}\n",
    "   1\\text{ when }i\\ne j\\text{ }  \\\\\n",
    "   0\\text{ when }i=j  \\\\\n",
    "\\end{matrix} \\right.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperplane to linearly separate the data becomes\n",
    "\n",
    "$$f(x_i) = \\sum_{i=1}^{m}{y_{i}\\Phi(x_i)} = 0$$\n",
    "\n",
    "so that for any $y_i > 0$, it returns $f(x_i) > 0$ and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this kenerl will leads to overfitting the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "421px",
    "left": "1px",
    "right": "1708px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
