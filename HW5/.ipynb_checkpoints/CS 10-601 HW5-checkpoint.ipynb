{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: VC Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "The maximum number of ways that the hypothesis space $H_1$ can label a set of n points is ${H_1}\\left[ n \\right]$. Assume that the $i$th way of labeling labels $m_i$ points as +1. Then within the $m_i$ points, hypothesis space $H_2$ has ${H_2}\\left[ m_i \\right]$ ways to further label them, which defines the intersection hypothesis space ${{H}^{*}}\\left[ n \\right]$. Therefore,\n",
    "\n",
    "$${{H}^{*}}\\left[ n \\right]=\\sum\\limits_{i=1}^{{{H}_{1}}\\left[ n \\right]}{{{H}_{2}}\\left[ {{m}_{i}} \\right]}\\le \\sum\\limits_{i=1}^{{{H}_{1}}\\left[ n \\right]}{{{H}_{2}}\\left[ n \\right]}={{H}_{1}}\\left[ n \\right]{{H}_{2}}\\left[ n \\right]$$\n",
    "\n",
    "The inequality is obtained due to the fact that the shattering coefficient of a hypothesis space monotoically increases as the set of points, i.e. for any $x >= y$, it follows\n",
    "\n",
    "$$ H\\left[ x \\right] \\ge H\\left[ y \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "By the definition, VC dimension of a hypothesis space $H$ is the cardinality of the largest set $S$ that can be shattered by $H$. $VC\\left(H\\right) = d$ is equivalent to  $\\left|S\\right| = d$. Then by the definition of shattering, the hypothesis space $H$ can split the set $S$ in $2^d$ ways, which is also the maximum number of ways to label d points of data. Therefore, it is obtained $$H[d] = 2^d$$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "Given that $VC\\left(H\\right) = d$, according to Sauer's lemma, we have $H\\left[d_*\\right]=O\\left({d_{*}}^{d}\\right)$.\n",
    "\n",
    "On the other hand, according to (b), for $VC\\left(H^*\\right) = d_*$, we have \n",
    "$H^*[d_*] = 2^{d_*}$. And according to (a), we have $H^*[d_*] \\le H[d_*]H[d_*]=O\\left({d_{*}}^{2d}\\right)$,\n",
    "\n",
    "That is \n",
    "\n",
    "$$\\begin{align}\n",
    " \\,\\text{    }{{2}^{{{d}_{*}}}}&\\le k{{d}_{*}}^{2d} \\\\ \n",
    " \\Rightarrow {{d}_{*}}&\\le \\log k+2 \\\\ \n",
    " \\Rightarrow {{d}_{*}}&={\\mathrm O}\\left( d\\log {{d}_{*}} \\right) \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "##### i. \n",
    "VC dimension is 2. For 2 points, no matter left +1, right -1 or vice versa, by setting the decision boundary in between these two points can always shatter the data. For 3 points, the hypothesis space cannot shatter the case +1, -1, +1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. \n",
    "\n",
    "VC dimension is 3. For 3 points that are not colinear, there will always be a vertical or horizontal boundary shatter the data. For 4 points, if the points form the shape of a convex quadrilateral, then the hypothesis space cannot shatter the case of one pair of diagonal points being the same class and the rest pair being the other class. On the other hands, if three of the four points form a triangle and the forth point is in the area of the triangle, then hypothesis space cannot shatter the case of the center point being different class other than de rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\n",
    "\n",
    "VC dimension is 3. The hypothesis space can shatter three non-colinear points. For the four points case, assume the four points being $\\left(x_i, y_i\\right), i \\in \\{1,2,3,4\\}$. Let the horizontal diameter be $d_x = max\\left(x_i\\right) - min\\left(x_i\\right)$ and vertical diameter be $d_y = max\\left(y_i\\right) - min\\left(y_i\\right)$. As long as two points defining $min\\left(d_x, d_y\\right)$ have differnt labels and two points defining $max\\left(d_x, d_y\\right)$ have the same label, the hypothesis space of square region will fail to shatter the data. The intuition is the edge length of the square has to be at least $max\\left(d_x, d_y\\right)$, while it is contradictory to the different labels defining $min\\left(d_x, d_y\\right)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 2: Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\n",
    "\n",
    "Variables $roads\\hspace{1mm}salted$ and $school\\hspace{1mm} cancellation$ are indepentdent of $temperature$ given that $snow$ is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\n",
    "\n",
    "No other variables are independent of $snow$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\n",
    "\n",
    "No other variables are independent of $snow$ given $temperature$ is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv.\n",
    "\n",
    "Variable $temperature$ is independent of $school\\hspace{1mm} cancellation$ given that $snow$ and  $roads\\hspace{1mm}salted$ are observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "\n",
    "For simplicity, the variables $temperature$, $snow$, $roads\\hspace{1mm}salted$ and $school\\hspace{1mm} cancellation$ are denoted as $t$, $s$, $rs$ and $sc$. According to the structure of the Bayes' Net, the joint probability becomes\n",
    "\n",
    "$$p\\left( t,s,rs,sc \\right)=p\\left( t \\right)p\\left( \\left. s \\right|t \\right)p\\left( \\left. rs \\right|s \\right)p\\left( \\left. sc \\right|s,rs \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "\n",
    "#### i.\n",
    "\n",
    "$$\\begin{align}\n",
    "& p\\left( t=cold,s=light,rs=F,sc=T \\right) \\\\ \n",
    "=&p\\left( t=cold \\right)p\\left( \\left. s=light \\right|t=cold \\right)p\\left( \\left. rs=F \\right|s=light \\right)p\\left( \\left. sc=T \\right|s=light,rs=F \\right) \\\\ \n",
    "=&0.4\\times 0.4\\times 0.1\\times 0.4 \\\\ \n",
    "=&0.0064 \\\\ \n",
    "\\end{align}$$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s \\right|sc=T,t=cold \\right) \\\\ \n",
    "  \\propto  &p\\left( s,sc=T,t=cold \\right) \\\\ \n",
    "  =&\\sum\\limits_{rs}{p\\left( s,rs,sc=T,t=cold \\right)} \\\\ \n",
    "  =&p\\left( t=cold \\right)p\\left( \\left. s \\right|t=cold \\right)\\sum\\limits_{rs}{p\\left( \\left. rs \\right|s \\right)p\\left( \\left. sc=T \\right|s,rs \\right)} \\\\ \n",
    "  \\propto &p\\left( \\left. s \\right|t=cold \\right)\\sum\\limits_{rs}{p\\left( \\left. rs \\right|s \\right)p\\left( \\left. sc=T \\right|s,rs \\right)} \\\\ \n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "By substituting the values from the table\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s=none \\right|sc=T,t=cold \\right)\\propto 0.4\\times \\left( 0.01\\times 0.01+0.99\\times 0.01 \\right)=0.004 \\\\ \n",
    " & p\\left( \\left. s=light \\right|sc=T,t=cold \\right)\\propto 0.4\\times \\left( 0.9\\times 0.2+0.1\\times 0.4 \\right)=0.088 \\\\ \n",
    " & p\\left( \\left. s=heavy \\right|sc=T,t=cold \\right)\\propto 0.2\\times \\left( 0.97\\times 0.95+0.03\\times 0.99 \\right)=0.19024 \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "After normalization\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s=none \\right|sc=T,t=cold \\right)=0.0142 \\\\ \n",
    " & p\\left( \\left. s=light \\right|sc=T,t=cold \\right)=0.3118 \\\\ \n",
    " & p\\left( \\left. s=heavy \\right|sc=T,t=cold \\right)=0.6740 \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s \\right|sc=F,t=cold \\right) \\\\ \n",
    "  \\propto  &p\\left( s,sc=F,t=cold \\right) \\\\ \n",
    "  =&\\sum\\limits_{rs}{p\\left( s,rs,sc=T,t=cold \\right)} \\\\ \n",
    "  =&p\\left( t=cold \\right)p\\left( \\left. s \\right|t=cold \\right)\\sum\\limits_{rs}{p\\left( \\left. rs \\right|s \\right)p\\left( \\left. sc=F \\right|s,rs \\right)} \\\\ \n",
    "  \\propto &p\\left( \\left. s \\right|t=cold \\right)\\sum\\limits_{rs}{p\\left( \\left. rs \\right|s \\right)p\\left( \\left. sc=F \\right|s,rs \\right)} \\\\ \n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "By substituting the values from the table\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s=none \\right|sc=T,t=cold \\right)\\propto 0.4\\times \\left( 0.01\\times 0.99+0.99\\times 0.99 \\right)=0.396 \\\\ \n",
    " & p\\left( \\left. s=light \\right|sc=T,t=cold \\right)\\propto 0.4\\times \\left( 0.9\\times 0.8+0.1\\times 0.6 \\right)=0.312 \\\\ \n",
    " & p\\left( \\left. s=heavy \\right|sc=T,t=cold \\right)\\propto 0.2\\times \\left( 0.97\\times 0.05+0.03\\times 0.01 \\right)=0.00976 \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "After normalization\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. s=none \\right|sc=T,t=cold \\right)=0.5517 \\\\ \n",
    " & p\\left( \\left. s=light \\right|sc=T,t=cold \\right)=0.4347 \\\\ \n",
    " & p\\left( \\left. s=heavy \\right|sc=T,t=cold \\right)=0.0136 \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv.\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. sc \\right|s=light \\right) \\\\ \n",
    " \\propto & p\\left( sc,s=light \\right) \\\\ \n",
    " =&\\sum\\limits_{t}{\\sum\\limits_{rs}{p\\left( sc,t,rs,s=light \\right)}} \\\\ \n",
    " =&\\sum\\limits_{t}{p\\left( t \\right)p\\left( \\left. s=light \\right|t \\right)\\sum\\limits_{rs}{p\\left( \\left. rs \\right|s=light \\right)p\\left( \\left. sc \\right|s=light,rs \\right)}} \\\\ \n",
    "\\propto& \\sum\\limits_{rs}{p\\left( \\left. rs \\right|s=light \\right)p\\left( \\left. sc \\right|s=light,rs \\right)} \\\\ \n",
    "\\end{align}$$\n",
    "\n",
    "By substituting the values from the table\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. sc=T \\right|s=light \\right)\\propto 0.9\\times 0.2+0.1\\times 0.4=0.22 \\\\ \n",
    " & p\\left( \\left. sc=F \\right|s=light \\right)\\propto 0.9\\times 0.8+0.1\\times 0.6=0.78 \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since the probability is already normalized, no more normalization is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v.\n",
    "\n",
    "Since $sc$ is independent of $t$ given that $s$ and $rs$ are observed.\n",
    "\n",
    "$$\\begin{align}\n",
    "  & p\\left( \\left. sc=T \\right|t=cold,s=light,rs=F \\right) \\\\ \n",
    " = &p\\left( \\left. sc=T \\right|s=light,rs=F \\right) \\\\ \n",
    " = &0.4 \\\\ \n",
    "\\end{align}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
